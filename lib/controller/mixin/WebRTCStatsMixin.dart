import 'dart:async';
import 'dart:convert';

import 'package:flutter_webrtc/flutter_webrtc.dart';

mixin WebRTCStatsMixin {
  RTCPeerConnection? get peerConnection;
  void log(String message);

  Timer? _statsTimer;

  // ç¼“å­˜ä¸Šæ¬¡çš„ bytesSent & timestampï¼Œç”¨äºè®¡ç®—å¸¦å®½
  final Map<String, _StatCache> _caches = {};

  void startStats({Duration interval = const Duration(seconds: 5)}) {
    _statsTimer?.cancel();
    _statsTimer = Timer.periodic(interval, (_) async {
      if (peerConnection?.connectionState ==
          RTCPeerConnectionState.RTCPeerConnectionStateConnected) {
        try {
          final reports = await peerConnection!.getStats();
          _reportKeyMetrics(reports);
        } catch (e) {
          log("è·å– Stats å¤±è´¥: $e");
          stopStats();
        }
      } else {
        stopStats();
      }
    });
    log("âœ… å·²å¯åŠ¨ Stats æ”¶é›†ï¼Œæ¯ ${interval.inSeconds}s ä¸€æ¬¡");
  }

  void stopStats() {
    _statsTimer?.cancel();
    _statsTimer = null;
    log("ğŸ›‘ å·²åœæ­¢ Stats æ”¶é›†");
  }

  void _reportKeyMetrics(List<StatsReport> reports) {
    int? packetsLost;
    double? rttSec;
    double? fps;
    int? width, height;
    int? bitrateBps;

    for (var r in reports) {
      final m = r.values;
      switch (r.type) {
        case 'outbound-rtp':
          // åªé’ˆå¯¹ video track è®¡ç®—
          if ((m['mediaType'] ?? m['kind']) == 'video') {
            final cache = _caches.putIfAbsent(r.id, () => _StatCache());
            bitrateBps = cache.computeBitrate(r);
          }
          break;
        case 'inbound-rtp':
          if ((m['mediaType'] ?? m['kind']) == 'video') {
            final rawLost = m['packetsLost'];
            packetsLost =
                rawLost is num ? rawLost.toInt() : int.tryParse(rawLost ?? '');
          }
          break;
        case 'candidate-pair':
          if (m['state'] == 'succeeded') {
            final rawRtt = m['currentRoundTripTime'];
            rttSec =
                rawRtt is num
                    ? rawRtt.toDouble()
                    : double.tryParse(rawRtt ?? '');
          }
          break;
        case 'track':
          if (m['kind'] == 'video') {
            final rawFps = m['framesPerSecond'];
            fps =
                rawFps is num
                    ? rawFps.toDouble()
                    : double.tryParse(rawFps ?? '');
            final rawW = m['frameWidth'], rawH = m['frameHeight'];
            width = rawW is num ? rawW.toInt() : int.tryParse(rawW ?? '');
            height = rawH is num ? rawH.toInt() : int.tryParse(rawH ?? '');
          }
          break;
      }
    }

    // æ„é€ ç»“æ„åŒ–è¾“å‡º

    //bitrate_bpsï¼ˆæ¯”ç‰¹ç‡â€¯bpsï¼‰
    //packets_lostï¼ˆä¸¢åŒ…æ•°ï¼‰
    //rtt_msï¼ˆå¾€è¿”æ—¶å»¶â€¯æ¯«ç§’ï¼‰
    //fpsï¼ˆå¸§ç‡â€¯FPSï¼‰
    //resolutionï¼ˆåˆ†è¾¨ç‡ï¼‰
    //timestampï¼ˆæ—¶é—´æˆ³ï¼‰
    final stats = {
      'bitrate_bps': bitrateBps,
      'packets_lost': packetsLost,
      'rtt_ms': rttSec != null ? (rttSec * 1000).round() : null,
      'fps': fps?.toStringAsFixed(1),
      'resolution':
          (width != null && height != null) ? '${width}x$height' : null,
      'timestamp': DateTime.now().toIso8601String(),
    };

    // æ¸…ç† null å­—æ®µï¼Œåªè¾“å‡ºå®é™…æ•°æ®
    stats.removeWhere((_, v) => v == null);

    log("WebRTC Stats â†’ ${jsonEncode(stats)}");
  }
}

/// ç”¨äºç¼“å­˜ä¸Šæ¬¡ bytesSent å’Œ timestampï¼Œå¹¶è®¡ç®—å¸¦å®½
class _StatCache {
  int? _lastBytes;
  double? _lastTs;

  int? computeBitrate(StatsReport report) {
    final raw = report.values['bytesSent'];
    final bytes = raw is num ? raw.toInt() : int.tryParse(raw ?? '');
    final ts = report.timestamp; // ms
    int? bps;
    if (_lastBytes != null && _lastTs != null && bytes != null) {
      final deltaB = bytes - _lastBytes!;
      final deltaS = (ts - _lastTs!) / 1000.0;
      if (deltaB > 0 && deltaS > 0) {
        bps = (deltaB * 8 / deltaS).round();
      }
    }
    _lastBytes = bytes;
    _lastTs = ts;
    return bps;
  }
}
